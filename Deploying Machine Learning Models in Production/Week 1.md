# Week 1

# Introduction

![Untitled](Week%201/Untitled.png)

![Untitled](Week%201/Untitled%201.png)

- 모델 서빙에서 모델을 훈련 시키는 것은 첫 번째 파트일 뿐!
- 모델 서빙은 최종적으로 사용자가 모델을 사용할 수 있도록 해야 합니다.

![Untitled](Week%201/Untitled%202.png)

- 프로덕션 환경에서 ML 모델을 서빙할 때 **모델**, **인터프리터**, **입력** 데이터를 고려해야 합니다.
- 이러한 구성 요소들은 예측을 계산하기 위해 모델에 의해 수집 되는 데이터를 얻기 위한 추론 프로세스에서 사용됩니다.

![Untitled](Week%201/Untitled%203.png)

- ML 워크플로우에서 모델 훈련은 배치 또는 정적 학습으로 이미 수집된 데이터에 대해 오프라인에서 수행됩니다.
- 프로덕션 환경으로 모델이 배포된 후 ML 모델은 실제 데이터를 접한 후에 빠르게 오래되기 때문에 다시 훈련될 때까지 일정하게 유지되게 됩니다. 이러한 현상을 모델 붕괴라고 합니다.
- 온라인 학습은 새로운 데이터가 들어오면 정기적으로 재학습을 합니다. 이러한 유형은 시계열 데이터를 사용하는 ML 시스템의 경우에 시간적 효과를 조정하기 위한 아이디어입니다.
- 모델로 예측을 진행할 때 두 가지 유형이 있습니다. 
1) 배치 예측은 ML 모델이 기록 입력 데이터를 기반으로 예측 집합을 만들게 됩니다. 이러한 예측은 시간에 의존적이지 않은 데이터나 실시간 예측이 중요하지 않은 경우에 사용됩니다.
2) 실시간 예측은 요청 시에 사용할 수 있는 데이터를 사용하여 실시간으로 모델을 생성합니다.

![Untitled](Week%201/Untitled%204.png)

- 온라인 추론을 최적화 할 때 중요한 지표: 대기시간, 처리량, 비용

![Untitled](Week%201/Untitled%205.png)

- 대기시간: 사용자의 액션과 그에 대한 app의 응답 사이의 지연
- 온라인에서 ML 추론은 데이터를 서버로 보내는 것부터 모델을 사용하여 추론하고 응답을 반환하는 전체 과정입니다.
- 이러한 과정에서 대부분의 app은 대기시간을 최소로 하는 것이 고객 만족도를 유지하는데 중요한 요구 사항입니다.

![Untitled](Week%201/Untitled%206.png)

- 처리량: 단위 시간에 제공된 성공적인 요청 수

![Untitled](Week%201/Untitled%207.png)

- 각각의 추론과 관련된 비용을 고려하도록 노력해야 합니다.
- 서비스 인프라에서는 CPU, GPU, Cache와 같은 비용을 고려해야 합니다.

![Untitled](Week%201/Untitled%208.png)

- 고객과 대면하는 app은 처리량을 최대화하고 대기시간을 최소화하는 것을 목표로 합니다.
- 일반적으로 고객과 대면하는 app은 특정 시점에 매우 높은 부하에 직면하게 되고 이를 처리하기 위해 높은 부하를 처리할 수 있는 인프라를 구축하여 사용자에게 짧은 대기 시간을 제공해야 합니다. 이와 같은 처리량과 대기 시간을 충족시키기 위해 인프라를 확장하면 비용이 증가할 수 있습니다.

![Untitled](Week%201/Untitled%209.png)

- 프로덕션에서 ML 모델을 실행하는 비용은 대기 시간과 처리량을 처리하기 위해 급격하게 증가될 수 있음
- 이를 위해 GPU와 같은 리소스를 공유하여 비용을 절감하고 여러 모델을 사용하여 처리량을 증가시키고, 모델 최적화를 탐색하는 등의 전략이 있음

![Untitled](Week%201/Untitled%2010.png)

![Untitled](Week%201/Untitled%2011.png)

- 정확도를 높이거나 더 복잡한 관계를 모델링하는 방법을 찾기 위해 모델이 점점 더 복잡해짐
- 이러한 경우에 예측 대기시간이 길어지지만 그래도 정확도가 향상되기를 기대함

![Untitled](Week%201/Untitled%2012.png)

- 하지만 모델이 더 복잡해지고 더 많은 피쳐가 포함되면 훈련과 배포 인프라의 모든 부분에 대한 리소스 요구 사항이 증가하게 됨
- 리소스 요구 사항이 증가하며 비용이 증가하고 더 큰 모델 레지스토리에 대한 하드웨어 요구 사항 관리가 증가하므로 지원 및 유지 관리 부담이 커지게 됨
- 따라서 핵심은 모델 예측의 효과와 지연 속도 사이에 균형을 찾는 것임

![Untitled](Week%201/Untitled%2013.png)

- 사용 사례에 따라서 두 가지 평가 지표를 결정해야 함
- 모델의 예측 효율성을 반영하는 지표로 정확도, 정밀도, 재현율이 있음 → 좋을수록 품질이 좋음
- 모델 게이팅 메트릭은 모델이 충족해야 하는 운영 제약 조건: 대기시간, 모델 크기, GPU 부하

![Untitled](Week%201/Untitled%2014.png)

- 모델 배포의 CPU, GPU를 지정
- 모델 복잡성 증가 → 모델의 성능 향상을 위해 해당 인프라에서 게이팅 메트릭에 도달할 때까지
- 결과 평가 후에 모델을 수용하거나 정확도를 개선하고 복잡성을 줄이거나 인프라 증가 결정

![Untitled](Week%201/Untitled%2015.png)

- 서버와 모델 훈련 인프라를 설계할 때 고려해야 할 요소로 GPU/TPU가 있음
- GPU는 포트를 통한 병렬에 최적화되는 경향이 있고 훈련 인프라에 자주 사용됨
- TPU는 추론 프로세스에서 대규모 모델 및 배치 크기에 이점이 있음
- GPU/TPU 같은 가속기 선택은 프로젝트 예산에 영향을 줄 수 있기 때문에 덜 효과적인 가속기를 다수 사용하는 것과 더 효과적인 가속기를 적게 사용하는 사이에 절충이 필요함
- 이러한 결정은 공유 리소스에 대한 부분도 고려해야 함

![Untitled](Week%201/Untitled%2016.png)

- ML 모델에 대한 예측 요청은 예측에 필요한 모든 피쳐들을 제공하지 않을 수 있음
- 일부 기능은 미리 계산된 후 데이터 스토어에서 실시간으로 읽어야 할 수 있음
- 이러한 시스템을 제공하기 위해서는 더 좋은 저장소가 필요하기 때문에 비용에 영향을 줌

![Untitled](Week%201/Untitled%2017.png)

- NoSQL DB는 caching 및 피쳐 조회를 구현하는데 좋은 솔루션임
- 수 천 개의 클라이언트에서 검색한 제한된 양의 빠르게 변화하는 데이터에 대해 ms 미만의 읽기 지연 시간이 필요한 경우 Google Cloud Memorystore가 효과적
Google Cloud Memorystore는 memory cache의 지연 시간에 대한 완전 관리형 버전 (물론 오픈소스도 있음)
- 스토리지가 자동으로 확장되는 천천히 변화하는 데이터에 대해 ms 미만의 읽기 지연 시간이 필요한 경우 Google Cloud Firestore가 효과적
- 선형적으로 확장할 수 있는 스토리지를 사용하여 데이터를 동적으로 변경하는데 ms 미만의 읽기 지연 시간이 필요한 경우 Google Cloud Bigtable이 효과적
- 이와 같이 요구 사항에 따라 사용 가능한 다양한 제품 중에서 선택 후 예산을 정해야 함

![Untitled](Week%201/Untitled%2018.png)

- 모델 배포를 위한 두 가지 방법이 있습니다.
→ 원격 호출을 통해서 접근하는 데이터 센터의 중앙 집중식 모델 사용
→ 모델의 인스턴스를 사용자에게 배포하여 모바일 또는 임베디드 시스템과 같은 로컬 환경 사용

![Untitled](Week%201/Untitled%2019.png)

![Untitled](Week%201/Untitled%2020.png)

- 데이터 센터에서는 대규모 데이터 센터에 대규모 리소스가 있는 경우에도 비용과 효율성이 모든 규모에서 중요함
- 다양한 기술을 활용하여 리소스 활용도를 개선하고 비용을 절감할 수 있도록 방법을 연구
- 휴대 전화와 같이 하드웨어에 제약 조건이 있는 경우에 복잡한 모델로 인해 배터리가 소모되거나 과열로 인해 제대로 동작하지 않을 수 있음
- 스토어의 경우에도 대용량 앱을 선호하지 않기 때문에 저장 용량에 제한이 있음

![Untitled](Week%201/Untitled%2021.png)

- 휴대 전화와 같이 하드웨어에 제약이 있는 경우 크고 복잡한 모델을 배포할 수 없음
- 대신에 모델을 서버에 배포한 다음 REST API를 통해 앱에서 추론에 사용할 수 있도록 할 수 있음
- 하지만 예측 대기 시간이 중요하거나 네트워크 연결이 불가능할 경우 적합하지 않음

![Untitled](Week%201/Untitled%2022.png)

- 일반적으로 가능한 한 추론 지연을 최소화하는 방식을 선택해야 함 
→ 이를 통해 앱의 응답 시간이 단축되어 사용자 경험이 향상됨
- 하지만 모델의 정확성이 중요한 경우에(질병 진단 등) 대기 시간은 중요하지 않을 수 있음

![Untitled](Week%201/Untitled%2023.png)

- 모델 복잡성, 크기, 정확도 및 예측 대기 시간 간에 균형을 유지하고 작업 중인 앱에 대한 각각의 비용과 제약 조건을 이해하는 것은 어려움
- 이러한 요소는 가장 적합한 모델을 선택하는데 영향을 줌
- EX) MobileNets → 가장 최신 기술은 아니지만 모바일 배포에 최적화 된 선택일 수 있음

![Untitled](Week%201/Untitled%2024.png)

- 모델 구축 및 선정 이후에는 프로파일링을 하고 벤치마크하는 것이 좋음
- 이를 통해 성능 병목 현상을 이해하고 계산 시간을 독점하는 실행장치를 식별할 수 있음
- 일반적으로 최적화를 진행하면 빠르고 에너지 효율적인 더 작은 모델을 만드는 것을 목표로 함
- 대기 시간이 중요한 앱의 경우 스레드 수를 늘려 실행속도를 높일 수 있지만, 모델은 더 많은 리소스와 전력을 사용하게 될 수 있음 → 적절한 조정이 필요?
- 또한 다중 스레드 사용은 동시에 실행 중인 다른 요소에 따라 성능 변동성이 증가하여 결과에 영향을 줄 수 있기 때문에 실제로 스레드 성능 평가를 통해 확인해야 함

![Untitled](Week%201/Untitled%2025.png)

- 다른 방법을 이용하여 모델을 서버로 배포하는 경우 서버를 설계하는 방법에 대한 몇 가지 고려사항이 있음
- 사용자가 요청을 할 수 있도록 웹 애플리케이션을 활용하고, 여기서 모델은 API 서비스의 형태로 제공됨
- Python 웹 프레임워크로 일반적으로 FastAPI, Flask, Django가 사용됨

![Untitled](Week%201/Untitled%2026.png)

- 앞서 설명한 웹 프레임워크 기반의 모델 서버는 모델 배포를 관리할 수 있음
- 클라이언터의 예측 요청을 서버에서 처리하기 때문에 커스텀 웹 어플리케이션을 따로 만들 필요가 없음
- 서버를 활용하기 때문에 모델 버전 관리가 용이하고, 요청 시 리소스가 필요할 때 모델을 load/unload 할 수 있음

![Untitled](Week%201/Untitled%2027.png)

- Clipper는 오픈 소스 모델 서버로 Cafe, TF, SKlearn과 같은 프레임워크에 구축된 다양한 모델을 배포하는데 도움이 됨
- Clipper에는 표준 REST 인터페이스가 포함되어 있어 프로덕션 어플리케이션과 쉽게 통합할 수 있음 → 모델에 구애 받지 않음
- Clipper는 클러스터와 리소스 관리를 위해 모델을 도커에 래핑하고 안정적인 지연 시간에 대한 서비스 수준을 설정하는데 도움이 됨

![Untitled](Week%201/Untitled%2028.png)

- Tensorflow Serving은 프로덕션 환경을 위해 설계된 ML 학습 모델을 위한 flexible high-performance 배포 시스템을 제공하는 오픈 소스 모델 서버
- TF Serving은 동일한 서버 아키텍처와 API를 유지하면서 다른 실험 환경에서 새로운 알고리즘을 쉽게 배포할 수 있음
- TF Serving은 TF 모델과 통합을 제공하지만 다른 유형의 모델 및 데이터를 제공하도록 확장할 수 있고 REST, gRPC protocol을 모두 제공함
- TF Serving은 코어당 초당 최대 10만개의 요청의 성능을 입증하여 ML 학습 앱으로 제공하기 위한 매우 좋은 tool
- 이외에도 동일한 모델의 다른 버전을 쉽게 load하고 rollback할 수 있는 버전 관리자가 있고, 클라이언트가 요청을 통해 원하는 버전을 선택할 수 있음

![Untitled](Week%201/Untitled%2029.png)

- 모델 배포에 있어 managed service를 사용하는 것이 유리함
- Google Cloud AI Platform Prediction Service를 통해 지연 시간이 짧은 예측을 제공하는 실시간 엔드포인트를 설정할 수 있고 이를 사용하여 데이터의 배치에 대한 예측을 얻을 수 있음
- 또한 GCP 자체에 학습된 모델을 배포할 수 있고, 트래픽에 따라 자동으로 확장할 수 있어 좋은 확장성과 동시에 비용 절감을 할 수 있음

![Untitled](Week%201/Untitled%2030.png)

![Untitled](Week%201/Untitled%2031.png)

- 자체 인프라를 구축하여 배포하는데 Tensorflow Serving은 이상적인 솔루션임
- Tensorflow Serving은 Docker 이미지를 사용하여 사용함

![Untitled](Week%201/Untitled%2032.png)

- Tensorflow-model-server binary는 SSE4 및 AVX와 같은 일부 플랫폼별 컴파일러 최적화를 사용하는 최적화된 서버, 구형 컴퓨터에서는 작동하지 않을 수 있음
- Tensorflow-model-server-universal는 기본 최적화로 컴파일되었기 때문에 대부분의 머신에서 동작함, 따라서 Tensorflow-model-server가 동작하지 않는 경우에 사용할 수 있음
- 두 패키지 모두 같은 binary 이름을 가지기 때문에 Tensorflow-model-server를 이미 설치했다면, 지운 이후에 설치해야함

![Untitled](Week%201/Untitled%2033.png)

- 필요에 맞게 커스텀을 진행하려는 경우 소스에서 Tensorflow Serving을 빌드할 수 있음

![Untitled](Week%201/Untitled%2034.png)

![Untitled](Week%201/Untitled%2035.png)

![Untitled](Week%201/Untitled%2036.png)

![Untitled](Week%201/Untitled%2037.png)

![Untitled](Week%201/Untitled%2038.png)

![Untitled](Week%201/Untitled%2039.png)

![Untitled](Week%201/Untitled%2040.png)

![Untitled](Week%201/Untitled%2041.png)

![Untitled](Week%201/Untitled%2042.png)

![Untitled](Week%201/Untitled%2043.png)

![Untitled](Week%201/Untitled%2044.png)

![Untitled](Week%201/Untitled%2045.png)